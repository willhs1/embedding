{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alembic==1.5.8 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.5.8)\n",
      "Requirement already satisfied: attrs==20.3.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (20.3.0)\n",
      "Requirement already satisfied: cliff==3.7.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.7.0)\n",
      "Requirement already satisfied: cmaes==0.8.2 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (0.8.2)\n",
      "Requirement already satisfied: cmd2==1.5.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: colorama==0.4.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (0.4.4)\n",
      "Requirement already satisfied: colorlog==5.0.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: greenlet==1.0.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata==4.0.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (4.0.1)\n",
      "Requirement already satisfied: joblib==1.0.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: jupyter in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (1.3.1)\n",
      "Requirement already satisfied: Mako==1.1.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (1.1.4)\n",
      "Requirement already satisfied: MarkupSafe==1.1.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: matplotlib==3.3.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (3.3.4)\n",
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (1.19.5)\n",
      "Requirement already satisfied: optuna==2.7.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 18)) (2.7.0)\n",
      "Requirement already satisfied: packaging==20.9 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 19)) (20.9)\n",
      "Collecting pandas==1.1.5 (from -r requirements.txt (line 20))\n",
      "  Using cached https://files.pythonhosted.org/packages/47/17/5c4b04caa8fe1dca2aa940dcc00319aa77c84fbdb71f83869a0900cac660/pandas-1.1.5-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: pbr==5.6.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 21)) (5.6.0)\n",
      "Requirement already satisfied: Pillow==8.2.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 22)) (8.2.0)\n",
      "Requirement already satisfied: prettytable==2.1.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 23)) (2.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 24)) (2.4.7)\n",
      "Requirement already satisfied: pyperclip==1.8.2 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 25)) (1.8.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 26)) (2.8.1)\n",
      "Requirement already satisfied: python-editor==1.0.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 27)) (1.0.4)\n",
      "Collecting pytz==2021.1 (from -r requirements.txt (line 28))\n",
      "  Using cached https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl\n",
      "Collecting scikit-learn==0.24.1 (from -r requirements.txt (line 29))\n",
      "  Using cached https://files.pythonhosted.org/packages/16/33/e0b09b2810e355b667cd3b28850c36963735a77a431efdb2c2ca1c1c5cea/scikit_learn-0.24.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: scipy==1.5.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 30)) (1.5.4)\n",
      "Requirement already satisfied: six==1.15.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 31)) (1.15.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 32)) (0.0)\n",
      "Requirement already satisfied: SQLAlchemy==1.4.11 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 33)) (1.4.11)\n",
      "Requirement already satisfied: stevedore==3.3.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 34)) (3.3.0)\n",
      "Collecting threadpoolctl==2.1.0 (from -r requirements.txt (line 35))\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm==4.60.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 36)) (4.60.0)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 37)) (3.7.4.3)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 38)) (0.2.5)\n",
      "Requirement already satisfied: zipp==3.4.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 39)) (3.4.1)\n",
      "Requirement already satisfied: PyYAML>=3.12 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from cliff==3.7.0->-r requirements.txt (line 3)) (5.1.2)\n",
      "Requirement already satisfied: pyreadline; sys_platform == \"win32\" and python_version < \"3.8\" in c:\\users\\willian\\anaconda3\\lib\\site-packages (from cmd2==1.5.0->-r requirements.txt (line 5)) (2.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (5.6.0)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (6.0.0)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (4.5.5)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (5.1.2)\n",
      "Requirement already satisfied: notebook in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (6.0.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter->-r requirements.txt (line 12)) (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (3.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.6.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.4.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.10.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (2.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.8.4)\n",
      "Requirement already satisfied: jupyter_client in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (5.3.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (7.8.0)\n",
      "Requirement already satisfied: prompt_toolkit<2.1.0,>=2.0.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.0.10)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\willian\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.0.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\willian\\anaconda3\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (18.1.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\willian\\anaconda3\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (3.5.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\willian\\anaconda3\\lib\\site-packages (from traitlets>=4.2->nbconvert->jupyter->-r requirements.txt (line 12)) (4.4.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 12)) (3.0.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\willian\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jupyter_client->jupyter-console->jupyter->-r requirements.txt (line 12)) (223)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.15.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 12)) (41.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 12)) (0.15.4)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\willian\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Installing collected packages: pytz, pandas, threadpoolctl, scikit-learn\n",
      "  Found existing installation: pytz 2019.3\n",
      "    Uninstalling pytz-2019.3:\n",
      "      Successfully uninstalled pytz-2019.3\n",
      "  Found existing installation: pandas 0.25.1\n",
      "    Uninstalling pandas-0.25.1:\n",
      "      Successfully uninstalled pandas-0.25.1\n",
      "  Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed pandas-1.1.5 pytz-2021.1 scikit-learn-0.24.1 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta prática iremos apresentar o uso de embeddings. Para isso, você deve primeiro instalar as dependencias usando `pip install -r requirements.txt` (ou `pip3`, dependendo da forma que seu python está instalado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, você deverá baixar os repositorios em português e inglês e salvá-los na pasta `embedding_data` seguindo as seguintes instruções: \n",
    "\n",
    "- [No respositório da USP](http://www.nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc) baixe [este arquivo (Glove 100 dimensões)](http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip). Ele possui  um pouco mais de 600 mil palavras retiradas de textos de páginas Web tais como a Wikipedia e canais de notícias [(Hartmann et al., 2017)](https://arxiv.org/abs/1708.06025). Descomprima e renomeie o arquivo txt para `glove.pt.100.txt`.\n",
    "\n",
    "- No [repositório de Stanford](https://nlp.stanford.edu/projects/glove/), baixe [este arquivo](http://nlp.stanford.edu/data/glove.6B.zip) use o arquivo . Este arquivo compreende ~400 mil palavras de textos extraidos da Wikipédia e [GigaWord](https://catalog.ldc.upenn.edu/LDC2011T07) [(Pennington et al., 2015)](https://nlp.stanford.edu/pubs/glove.pdf). Descomprima e salve o arquivo com embeddings de 100 dimensões (nome `glove.6B.100d.txt`) na pasta `embedding_data` renomeando esse arquivo para `glove.en.100.txt`.\n",
    "\n",
    "Como você pode perceber, esta prática demandará um espaço livre em disco de aproximadamente 3GB. Os arquivos estão no seguinte formato: em cada linha, uma palavra e N valores representando o valor em cada uma das N dimensões do embedding desta palavra. Por exemplo, caso as palavras `casa`, `redondel` e `rei` sejam representadas por um embedding de 4 dimensões, uma possível representação seria:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "casa 0.12 0.1 0.5 -0.4\n",
    "redondel 0.2 0.1 -0.4 0.5\n",
    "rei 0.1 0.5 -0.1 0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `get_embedding`, do arquivo `embeddings/utils.py` é responsável por ler esse arquivo e gerar um dicionário em que a chave é a palavra e o valor é sua representação por meio de embeddings. Para a  representação acima, a saída desta função seria seria: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'casa': array([ 0.12,  0.1 ,  0.5 , -0.4 ]),\n",
       " 'redondel': array([ 0.2,  0.1, -0.4,  0.5]),\n",
       " 'rei': array([ 0.1,  0.5, -0.1,  0.1])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dict_embedding_ex = {\n",
    "                        \"casa\":np.array([0.12,0.1,0.5,-0.4]),\n",
    "                        \"redondel\":np.array([0.2,0.1,-0.4,0.5]),\n",
    "                        \"rei\":np.array([0.1,0.5,-0.1,0.1]),\n",
    "                    }\n",
    "dict_embedding_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa função, também é salvo o objeto criado usando [pickle](https://docs.python.org/3/library/pickle.html), assim, a próxima vez que seja lido o embedding, a leitura será mais rápida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - obtenção do embedding**: Complete a função `get_embedding` obtendo a palavra e o vetor de embeddings com a dimensão `embeddings_size` substituindo os `None` apropriadamente. O dataset possui algumas incosistencias que você deve considerar ao modificar essas linhas: no dataset em português, a maioria das palavras compostas são separadas por hífen, porém, foi verificado que umas palavras foi separado por espaço. Por caso disso, você deve considerar que as `embeddings_size` últimas posições são os valores de cada dimensão, separados por espaço e, as demais, são a palavra. Sugiro \"brincar\" abaixo com o uso de [índice negativo](https://www.geeksforgeeks.org/python-negative-index-of-element-in-list/) entenda também o [método join](https://www.geeksforgeeks.org/join-function-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pé de moleque': [ 0.1 -0.5  0.5  0.1 -0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "linha = \"pé de moleque 0.1 -0.5 0.5 0.1 -0.5\"\n",
    "embedding_size = 5\n",
    "arr_line = linha.strip().split()\n",
    "\n",
    "word = \" \".join(arr_line[0:(len(arr_line)-embedding_size)])\n",
    "#colocamos float16 para economizar memória\n",
    "embedding = np.array(arr_line[len(arr_line)-embedding_size:], dtype=np.float16)\n",
    "print(f\"'{word}': {embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o teste unitário abaixo para verificar o funcionamento do `get_embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Willian\\Desktop\\RI\\ap-de-maquina-embedding-master\\embeddings\\embedding_tests.py\", line 2, in <module>\n",
      "    from embeddings.utils import *\n",
      "  File \"C:\\Users\\Willian\\Desktop\\RI\\ap-de-maquina-embedding-master\\embeddings\\utils.py\", line 1, in <module>\n",
      "    from sklearn.decomposition import PCA\n",
      "ModuleNotFoundError: No module named 'sklearn'\n"
     ]
    }
   ],
   "source": [
    "!python3 -m embeddings.embedding_tests TestEmbeddings.test_get_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute os embeddings em português e ingles. Não se preocupe com as palavras ignoradas: foram algumas inconsistencias no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: the\n",
      "LInha com erro: 'port -0.94451 -0.41918 0.16819 -0.67172 -0.061914 -0.47964 -0.5344 0.45761 0.59723 0.51453 -0.31172 -0.44673 -0.041649 -0.098756 -0.19791 -1.4892 0.82108 -0.72552 -0.32739 0.46094 0.66842 -0.19532 0.34386 -0.50672 0.30778 -0.30816 -0.73175 -0.31235 0.19399 0.13519 -0.53491 -0.21284 0.47458 0.040454 0.38752 -0.049032 0.06913 0.46416 0.055362 -0.12081 0.055125 -1.7246 0.3235 -0.35086 0.90604 1.0472 -0.029213 -0.60464 0.79627 1.1108 0.28675 0.68702 0.40203 0.64777 -0.55304 -1.5814 -1.4324 -1.3822 1.7227 -0.15305 -0.79066 -0.24519 -0.66218 -0.38436 -0.55682 0.12663 -0.59544 0.046581 -0.3353 0.12981 -0.7238 -0.107 0.27073 -0.60108 0.36972 -0.046519 0.8031 0.3818 -0.8024 0.6256 0.44167 0.088033 -0.78446 1.1189 -0.74748 0.5858 0.30813 -0.39637 0.34147 -0.60128 0.56194 0.27767 -0.51396 -0.0075831 -0.044894 0.94605 -0.54196 -0.0074126 0.89228 0.082159\n",
      "'\n",
      "Palavras ignoradas: 1\n",
      "LInha com erro: 'afeta -0.536855 -0.007495 -0.013442 0.010075 -0.431695 -0.954242 -0.568022 0.298830 0.206329 0.221990 0.448505 0.324589 0.155598 -0.434498 -0.038841 0.351460 -0.219903 0.292218 -0.116971 0.102685 0.944467 0.388329 -0.330937 -0.755884 -0.164395 0.377288 -0.361163 -0.915998 0.161222 0.827306 -0.284279 0.053623 -0.500227 0.372490 -0.171850 -0.247056 0.115936 -0.017340 -0.118077 -0.008613 0.009058 -0.344892 0.526107 0.021267 0.123609 0.112071 0.277755 -0.655675 0.056385 -0.489364 -0.011241 -0.068256 -0.050418 0.283620 1.146130 -1.045703 0.120836 0.311448 -0.007991 -0.395445 -0.616343 -0.102998 0.801631 0.035789 0.522152 -0.000360 0.081070 0.359324 0.164685 0.103358 -0.434422 -0.047618 0.685093 -0.245462 0.899385 0.430083 -0.097732 -0.991104 0.267290 0.055047 0.469607 -0.454359 -0.206270 -0.075901 -0.702083 -0.149101 0.101842 -0.126275 0.175566 -0.050471 -0.131559 0.382135 -0.021810 -0.609549 0.137217 -0.443079 -0.909590 -0.520087 0.576502 -0.078572\n",
      "'\n",
      "Palavras ignoradas: 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from embeddings.utils import get_embedding, plot_words_embeddings\n",
    "\n",
    "str_dataset = \"glove.en.100.txt\"\n",
    "dict_embedding_en = get_embedding(str_dataset)\n",
    "str_dataset = \"glove.pt.100.txt\"\n",
    "dict_embedding_pt = get_embedding(str_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `plot_words_embeddings` utiliza [Análise de Componentes Principais](https://pt.wikipedia.org/wiki/An%C3%A1lise_de_componentes_principais) (PCA, do inglês Principal Component Analisys) para reduzir cada embedding em 2 dimensões para, logo após, plotar em um grafico a posição dessas palavras de acordo com o embedding. Veja o grafico apresentado abaixo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_to_use = {\n",
    "                        \"en\":\n",
    "                            {\"embedding\":dict_embedding_en,\n",
    "                            \"words_to_use\":[\"prince\",\"princess\",\n",
    "                                            \"duchess\", \"duke\", \"countess\", \"marquis\", \n",
    "                                            \"marquise\",\"king\",\"queen\",\n",
    "                                            \"girl\",\"boy\",\"man\",\"woman\",\"child\",\n",
    "                                           \"dog\",\"cat\",\"mouse\"]},\n",
    "\n",
    "                        \"pt\":{\"embedding\":dict_embedding_pt,\n",
    "                          \"words_to_use\":[\"principe\",\"rei\",\"rainha\",\"conde\",\"duquesa\",\"duque\",\"condessa\",\n",
    "                           \"marquês\",\"marquesa\",\n",
    "                           \"homem\",\"mulher\",\"princesa\",\"menina\",\"menino\",\"criança\",\n",
    "                           \"garoto\",\"garota\",\n",
    "                            \"arroz\",\"feijão\"]}\n",
    "                }\n",
    "\n",
    "language = \"pt\"#mude de 'pt' para 'en' para ver em ingles tb!\n",
    "plot_words_embeddings(embeddings_to_use[language][\"embedding\"], \n",
    "                    embeddings_to_use[language][\"words_to_use\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo acima, em português, veja que podemos pensar em dois conceitos claramente divididos: a realeza e o gênero. Pense, neste plano cartesiano: qual eixo corresponde ao conceito de realeza? E o de gênero? Perceba que \"criança\" deveria ter genero neutro - de fato, está mais próximo do zero. Porém, pode haver algum ruído associando a palavra criança ao genero feminino. Isso, em português, pode haver uma explicação, pois utilizamos  o artigo `a`, usado para palavras que remetem ao genero feminino, para se referir a criança. Assim, em português, os artigos podem aproximar uma palavra de genero neutro a um determinado genero.\n",
    "\n",
    "\n",
    "Em inglês, não foi possível verificar tão bem a divisão entre os conceitos de `genero` e `realeza`. Isso pode ocorrer devido a redução de dimensionalidade: os conceitos não necessariamente correspondem a um eixo no plano cartesiano e, mesmo se corresponder, ao mapear itens com $n$ dimensões para um plano bidimensional, pode haver perda de informação. Mesmo assim, conseguimos ver a separação entre palavras da realeza e que não são da realeza. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinta-se livre para \"brincar\", alterando/adicionando palavras. Por exemplo, adicione animais. Devido à ambiguidades, ao dataset e à própria redução de dimensionalidade, podem existir palavras que estão erroneamente próximas, se considerarmos o conceito das mesmas,  principalmente se adicionarmos palavras de conceitos muito distintos. Um detalhe: no dataset em português, há uso de palavras compostas e elas estão (geralmente) separadas por hífen. No dataset em inglês não há palavras compostas.\n",
    "\n",
    "Tanto nesta tarefa quanto na próxima você poderá perceber que os embeddings podem carregar preconceitos. Há uma forma de modificar os vetores para eliminar um determinado tipo de preconceito. Por exemplo, nesses embeddings existirão palavras erronemente similares a um determinado genero e, para corrigir, é possível deixar todas as palavras sem distinção pelo genero. Caso queira saber como minimizar esse problema, veja o artigo \"[Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)\". O título do artigo se remete a um preconceito descoberto ao usar analogias, que será o próximo tópico desta prática. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de analogias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra caracteristica muito interessante ao usar embedding é a criação de analogias. Por exemplo, na frase `homem está para mulher assim como rei está para...`, fazendo operações com os _embeddings_, muitas vezes é possível chegar na analogia mais provável que, neste caso, seria a palavra `rainha`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - calculo da analogia: ** Nesta atividade, iremos implementar o método `calcula_embedding_analogia` da classe `Analogy`. Essa classe tem acesso ao dicionário de embeddings e a estrutura KDTree, que iremos explicá-la posteriormente. Considerando a frase <span style=\"color:blue\">\"**palavra_x** está para **palavra_y** assim como **assim_como** esta para **palavra_z**\"</span>, o método `calcula_embedding_analogia` recebe como parametro as palavras `palavra_x`, `esta_para` e `assim_ como` e retorna um embedding que, possivelmente, será muito próximo da `palavra_z`. \n",
    "\n",
    "Veja [na aula](https://docs.google.com/presentation/d/1-CggYUA2s7LW7_LcnGv7vlpUGFg9kEWG0j6lWGUnaLI/edit?usp=sharing) como é feito o calculo e, logo após, faça o teste unitário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.0, -1.0, -1.0, ]\n",
      "[ 12.296875, 53.09375, 30.984375, ]\n",
      "[ -10.96875, -30.90625, -9.6015625, ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2, 3],[-1.2, 3.2, 1.2],[12.2, 31.2, 11.2]], dtype=np.float16)\n",
    "esta_para = np.array([[-3, 0, 1],[11, 56, 32.2],[0, 0.2, 0.4]], dtype=np.float16)\n",
    "assim_como = np.array([[2, 1, 1],[0.1,0.3,0],[1.23, 0.1, 1.2]], dtype=np.float16)\n",
    "\n",
    "for i,x_val in enumerate(x):\n",
    "    arr_embedding = assim_como[i]-x[i]+esta_para[i]\n",
    "    print(\"[\",end=\" \")\n",
    "    for val in arr_embedding:\n",
    "        print(float(val),end=\", \")\n",
    "    print(\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [1. 2. 3.] esta para: [-3.  0.  1.] assim_como: [2. 1. 1.]\r\n",
      "x: [-1.2  3.2  1.2] esta para: [11.  56.  32.2] assim_como: [1. 2. 1.]\r\n",
      "x: [12.2 31.2 11.2] esta para: [0.  0.2 0.4] assim_como: [1.23 0.1  1.2 ]\r\n",
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.002s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m embeddings.embedding_tests TestEmbeddings.test_calculo_analogia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - busca da palavra mais similar:** O calculo da atividade anterior resultou em um embedding e, agora, precisamos  procuramos a palavra mais próxima a este embedding obtido. Para isso, precisamos de: (1) uma forma eficiente para percorrer os embeddings para descobrir o mais similar; (2) uma métrica de similaridade/distancia; \n",
    "\n",
    "**Como percorrer embeddings?** Para encontrarmos os embeddings similares, uma alternativa seria percorrer todos os vetores de embeddings e encontrar o mais similar. Porém, como estamos trabalhando com centenas de milhares de embeddings, essa operação seria muito custosa. Para isso, podemos usar uma estrutura de dados chamada **KDTree**. KDtree é uma arvore que organiza dados espaciais de tal forma que conseguimos alcançar elementos similares de forma mais eficiente. Caso esteja interessado em mais detalhes, [veja este video](https://www.youtube.com/watch?v=Glp7THUpGow).\n",
    "\n",
    "**Qual métrica de distancia/similaridade usaremos?**  Já foi demonstrado que esta métrica é eficiente para similaridade entre embeddings é a distancia euclidiana [(Pennington et al., 2015)](https://nlp.stanford.edu/pubs/glove.pdf). A [distancia euclidiana](https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_euclidiana) entre dois pontos $p$ e $q$ é calculada por meio do tamanho da linha entre esses pontos. Para um espaço bidimensional, considerando que os pontos $p$ e $q$ são representados pelas coordenadas $(p_1,p_2)$ e $(q_1,q_2)$, respectivamente, a equação é dada pela seguinte fórmula: $d(p,q) = \\sqrt{(p_1-q_1)^2+(p_2-q_2)^2}$ veja uma representação gráfica: \n",
    "\n",
    "<img width=\"400px\" src=\"img/distancia_euclidiana.svg\">\n",
    "\n",
    "Esta métrica pode ser generalizada para um espaço n-dimensional e o cálculo seria: $d(p,q) = \\sqrt{(p_1-q_1)^2+(p_2-q_2)^2+...+(p_n-q_n)^n}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, nesta atividade iremos utilizar [a implementação do kdtree do scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html). Nessa estrutura, é possível armazenar os embeddings e, logo após fazer consultas eficiente para, por exemplo, procurar os k elementos mais próximos. Veja o exemplo abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O ponto [3, 3] é o 1º ponto mais próximo de [3, 2] distância: 1.0\n",
      "O ponto [2, 2] é o 2º ponto mais próximo de [3, 2] distância: 1.0\n",
      "O ponto [1, 1] é o 3º ponto mais próximo de [3, 2] distância: 2.23606797749979\n",
      "O ponto [4, 4] é o 4º ponto mais próximo de [3, 2] distância: 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "elementos = [[1,1],\n",
    "             [2,2],\n",
    "             [3,3],\n",
    "             [4,4],\n",
    "             [5,5],\n",
    "             [6,6],\n",
    "             ]\n",
    "#os elementos são passados como parametro na construção do KDTree junto com a métrica \n",
    "#de distancia que iremos usar\n",
    "kdtree = KDTree(elementos,  metric='euclidean')\n",
    "\n",
    "#retorna os 2 elementos mais próximos e sua distancia\n",
    "#como podemos fazer uma consulta por lista de pontos, temos que \n",
    "#passar uma lista de pontos como parametro\n",
    "ponto = [3,2]\n",
    "distancia,pos_mais_prox = kdtree.query([ponto], k=4, return_distance=True)\n",
    "for i,pos in enumerate(pos_mais_prox[0]):\n",
    "    elemento = elementos[pos]\n",
    "    distancia_ponto = distancia[0][i]\n",
    "    print(f\"O ponto {elemento} é o {i+1}º ponto mais próximo de {ponto} distância: {distancia_ponto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, cada embedding pode ser armazenado no KTree para, logo após, obtermos os embeddings mais próximos a um embedding em questão. Não é possível armazenar na estrutura do KDTree a palavra referente a cada embedding representado, por isso, armazenamos essa estrutura como um atributo da classe `KDTreeEmbedding` (arquivo `utils.py`) que armazena também os atributos `pos_to_word` mapeando, para cada posição a palavra correspondente e o atributo `word_to_pos` que faz o oposto: mapeia, para cada palavra, a posição correspondente. Veja no construtor de `KDTreeEmbedding`  como é criado o KDTree. Nela, também será salvo um arquivo com a implementação do KDtree e os atributos `pot_to_word` e `word_to_pos` isso é necessário pois a criação da KDTree é muito custosa.\n",
    "\n",
    "\n",
    "Nesta atividade, você deverá implementar `get_most_similar_embedding` que obtém as $k$ palavras mais similares à palavra (ou embedding) representado pelo parametro `query` por meio do método `query` da KDTree. O parâmetro `query` pode ser a palavra (`string`) ou o proprio embedding (`np.array`). Logo após, implemente também o método `get_embeddings_by_similarity` que utiliza o método `query_radius` ([veja documentação](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree.query_radius)) que retorna todas as palavras que estão em um raio de `max_distance` da palavra alvo especificada pelo parametro `query`. Para ambas as implementações, utiliza-se o método `positions_to_word`, já implementado, para retornar as palavras de acordo com as posições indicadas. Caso haja alguma palavra a ser ignorada em `words_to_ignore` ela será excluída também no método `positions_to_word`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m embeddings.embedding_tests TestEmbeddings.test_get_most_similar_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 0.001s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m embeddings.embedding_tests TestEmbeddings.test_embeddings_by_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você pode testar os métodos utilizando os datasets de embeddings. Lembre-se  que o KDTree pode demorar mais de 30 minutos para ser criado na primeira execução de cada idioma. Caso queira testar para o ingles, não esqueça de mudar de `\"kdtree.pt.p\"` para `\"kdtree.en.p\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: distribuída\n",
      "20000: diferenciados\n",
      "30000: socialite\n",
      "40000: bárbaras\n",
      "50000: seguro-desemprego\n",
      "60000: interligada\n",
      "70000: landi\n",
      "80000: hurts\n",
      "90000: jackeline\n",
      "100000: cataluña\n",
      "110000: héber\n",
      "120000: calama\n",
      "130000: afogue\n",
      "140000: natalícios\n",
      "150000: amostrada\n",
      "160000: portageiros\n",
      "170000: ozias\n",
      "180000: banerjee\n",
      "190000: crackdown\n",
      "200000: kirchspielslandgemeinde\n",
      "210000: yello\n",
      "220000: picrodendraceae\n",
      "230000: rochlitz\n",
      "240000: illis\n",
      "250000: oitis\n",
      "260000: kalki\n",
      "270000: autorizagäo\n",
      "280000: goleminov\n",
      "290000: mamita\n",
      "300000: interessarmos\n",
      "310000: cprp\n",
      "320000: samitier\n",
      "330000: dimitre\n",
      "340000: montegranaro\n",
      "350000: sanguineti\n",
      "360000: wurmser\n",
      "370000: villaronga\n",
      "380000: zimbra\n",
      "390000: salvini-plawen\n",
      "400000: pankisi\n",
      "410000: hi-c\n",
      "420000: boggio\n",
      "430000: super-pena\n",
      "440000: imecc\n",
      "450000: adamascados\n",
      "460000: nikolaeva\n",
      "470000: chi0\n",
      "480000: neuropatológicas\n",
      "490000: atulmente\n",
      "500000: megainvestigação\n",
      "510000: analista-tributário\n",
      "520000: gitirana\n",
      "530000: quidação\n",
      "540000: baios\n",
      "550000: jefa\n",
      "560000: tae-hyun\n",
      "570000: celebuzz\n",
      "580000: heparan\n",
      "590000: palomonte\n",
      "600000: tuymans\n",
      "610000: comaroff\n",
      "620000: jōdai\n",
      "630000: republicanista\n",
      "640000: aglutinar-se\n",
      "650000: colonist\n",
      "660000: fronteia\n",
      "670000: locomoviam-se\n",
      "680000: podlasie\n",
      "690000: tamtert\n",
      "700000: alvalde\n",
      "710000: decoimas\n",
      "720000: holdstock\n",
      "730000: notificou-os\n",
      "740000: sipylum\n",
      "750000: 0000px\n",
      "760000: batumbulan\n",
      "770000: conisania\n",
      "780000: ergoldsbach\n",
      "790000: harlington-straker\n",
      "800000: lanley\n",
      "810000: navigabilidade\n",
      "820000: prolongarse\n",
      "830000: sitophilus\n",
      "840000: vassilko\n",
      "850000: ajuda-pinto\n",
      "860000: canaã£,\n",
      "870000: dewberry\n",
      "880000: fritagem\n",
      "890000: kepple\n",
      "900000: nauticos\n",
      "910000: quartel-central\n",
      "920000: successi\n",
      "Palavras ignoradas: 2\n",
      "Entra aki\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40271/3594534953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkdtree_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"kdtree.pt.p\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdict_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKDTreeEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkdtree_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mkdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_most_similar_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"carro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ap-de-maquina-embedding-master/embeddings/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dict_embedding, kdtree_file, overwrite_kdtree)\u001b[0m\n\u001b[1;32m    166\u001b[0m                              \u001b[0;34m\"pos_to_word\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_to_word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                              \"word_to_pos\":self.word_to_pos},kd_file)\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpositions_to_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnearest_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_to_ignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_to_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
    "str_dataset = \"glove.pt.100.txt\"\n",
    "kdtree_file = \"kdtree.pt.p\"\n",
    "dict_embedding = get_embedding(str_dataset)\n",
    "kdtree = KDTreeEmbedding(dict_embedding, kdtree_file)\n",
    "kdtree.get_most_similar_embedding(\"carro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - 💞 apresentando as analogias 💞:** Agora você deverá implementar o método `analogia` da classe `Analogy` que deverá utilizar os métodos `calcula_embedding_analogia` e o `get_most_similar_embedding` para retornar as 4 palavras mais prováveis para completar uma determinada analogia, com os parametros indicados. Caso, dentre as 4 palavras, haja uma palavra dos parametro de entrada, a mesma pode ser excluída, retorando menos palavras. Por exemplo, considerando \"**rei** está para **rainha** assim como **homem** está para...\" uma caso uma das palavras de saída para essaa entrada  seja `rainha`, o método poderá retornar 3 palavras (eliminando a palavra rainha). Isso já é considerado no método `get_most_similar_embedding`. Lembre-se que o método `get_most_similar_embedding` é da classe KDTreeEmbedding e a `Analogy`possui o atributo `kdtree_embedding` que é uma instancia da classe `KDTreeEmbedding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m embeddings.embedding_tests TestEmbeddings.test_analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja as analogias (brinque a vontantade com a representação em português e em inglês)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.utils import *\n",
    "dict_embedding = get_embedding( \"glove.pt.100.txt\",100)\n",
    "obj_analogy = Analogy(dict_embedding,\"kdtree.pt.p\")\n",
    "\n",
    "\n",
    "dict_analogias = {(\"brasil\",\"brasilia\"):[\"peru\",\"gana\",\"japão\",\"espanha\",\"india\"],\n",
    "                  (\"bahia\",\"salvador\"):[\"acre\",\"alagoas\",\"amapá\",\"amazonas\",\"ceará\",\"goiás\"],\n",
    "                  (\"brasil\",\"feijoada\"):[\"italia\",\"estados-unidos\",\"inglaterra\",\"argentina\",\"peru\"],\n",
    "                  (\"homem\",\"mulher\"):[\"garoto\",\"rei\",\"príncipe\",\"pai\",\"cavalo\",\"garçon\"],\n",
    "                  (\"grande\",\"pequeno\"):[\"cheio\",\"alto\",\"forte\",\"largo\"],\n",
    "                  (\"pelé\",\"futebol\"):[\"tyson\",\"bolt\",\"senna\"],\n",
    "                  (\"atena\",\"sabedoria\"):[\"afrodite\",\"poseidon\",\"zeus\",\"atena\"],\n",
    "                  (\"cruzeiro\",\"raposa\"):[\"atlético\",\"gremio\",\"palmeiras\",\"corinthians\"],\n",
    "                 }\n",
    "\n",
    "for (palavra,esta_para), arr_assim_como in dict_analogias.items():\n",
    "    print(f\"{palavra} está para {esta_para} assim como...\")\n",
    "    for assim_como in arr_assim_como:\n",
    "        palavras = obj_analogy.analogia(palavra,esta_para,assim_como)\n",
    "        print(f\"\\t{assim_como} está para {palavras[0]} (ou {palavras[1:]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma limitação desses embeddings é a dependencia de idioma e que palavras ambiguas não são tratadas. Por exemplo, Jaguar pode ser uma marca de carro ou animal, dependendo do contexto.  Para diminuir o problema de ambuiguidades, o [BERT](https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/) é um embedding que a representação da palavra é diferente de acordo com o seu contexto. O [MUSE](https://github.com/facebookresearch/MUSE) é um embedding multilingue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representação textual usando embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes, precisamos de um único vetor para representar uma frase ou um texto ainda maior. Para isso, podemos usar a representação Bag of Words ou, ainda, representar por palavras chaves ou utilizarmos uma combinação de nossas representações por palavras. Neste tutorial, iremos mostrar como combinar embeddings de palavras e usar a representação por palavras chaves - podendo, inclusive, fazer uma expansão de palavras chaves por embeddings.\n",
    "\n",
    "Para isso, iremos usar o seguinte contexto: por meio de um dataset de revisões de produto da amazon, deseja-se prever automaticamente o sentimento do mesmo (positivo ou negativo). Utilizou-se uma amostra do [dataset do Kaggle para este exemplo](https://www.kaggle.com/bittlingmayer/amazonreviews). Veja abaixo o dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_amazon_reviews = pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")\n",
    "df_amazon_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em um método de aprendizado de maquina, cada instancia deve ser representada por um vetor numérico utilizando as representações ditas anteriormente. Iremos ilustrar cada exemplo utilizando uma pequena subamostra desta amostra com 5 exemplos positivos e 5 negativos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_amazon_reviews[df_amazon_reviews[\"class\"]==\"positive\"][:5]\n",
    "df_negative = df_amazon_reviews[df_amazon_reviews[\"class\"]==\"negative\"][:5]\n",
    "df_amazon_mini = pd.concat([df_positive,df_negative])\n",
    "df_amazon_mini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of words: ** um exemplo simples, sem usar embeddings, é a representação em bag of words, **já discutido aqui**. Assim, podemos  usar a classe `BagOfWords` que está no arquivo `textual_representation.py`. Para as representações bag of words, usaremos a função bag_of_words abaixo. Usando esta representação o nosso dataset ficaria representado da seguinte forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.textual_representation import BagOfWords\n",
    "#o vocabulario, quando vazio, será considerado todas as palavra (menos stopwords)\n",
    "def bag_of_words(data, vocabulary=None):\n",
    "    #obtem stopwords\n",
    "    stop_words = set()\n",
    "    with open(\"datasets/stopwords.txt\") as stop_file:\n",
    "        stop_words = set(stop_word[:-1] for stop_word in stop_file)\n",
    "\n",
    "    #instancia o bag of words, filtrando stopwords e considerando o vocabulario (se possivel)\n",
    "    bow = BagOfWords(\"bow\", stop_words=list(stop_words), words_to_consider=vocabulary)\n",
    "    \n",
    "    #o bag of words, é gerado separadamente a representação do treino e teste\n",
    "    #iremos usar apenas a representação considerando que \"data\" é o treino\n",
    "    data_preproc = bow.preprocess_train_dataset(data, \"class\")\n",
    "\n",
    "    #exibe apenas colunas não zedadas\n",
    "    m2 = (data_preproc != 0).any()\n",
    "    data_preproc = data_preproc[m2.index[m2].tolist()]\n",
    "    \n",
    "    return data_preproc\n",
    "bag_of_words(df_amazon_mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of words (filtrado por palavras chaves e embeddings similares)** Como bag of words é uma representação com milhares de atributos, poderiamos fazer uma restrição por palavras chaves. Por exemplo, caso usássemos como vocabulário do bag of words baseado nas palavras obtidas da roda de emoções porposta por [Scherer K., (2005)](https://journals.sagepub.com/doi/pdf/10.1177/0539018405058216): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_words = {\n",
    "                    \"pride\":{\"proud\"},\n",
    "                    \"elation\":{\"ecstatic\", \"euphoria\", \"exaltation\", \"exhilarating\"},\n",
    "                    \"happiness\":{\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"},\n",
    "                    \"satisfaction\":{\"comfortable\",\"contentment\"},\n",
    "                    \"relief\":{},\n",
    "                    \"hope\":{\"buoyancy\", \"confident\", \"faith\", \"optimistic\"},\n",
    "                    \"interest\":{\"alert\", \"animation\", \"ardor\", \"curious\",\"enthusiasm\"},\n",
    "                    \"surprise\":{\"amazed\", \"astonishing\", \"dumbfounded\",\"thunderstruck\"},\n",
    "                    \"anxiety\":{\"anguish\",\"anxiety\",\"apprehensive\",\"jittery\",\"nervous\",\"worry\"},\n",
    "                    \"sadness\":{\"chagrin\", \"dejected\", \"gloom\", \"hopeless\", \"melancholy\", \"sad\", \"tear\"},\n",
    "                    \"boredom\":{\"ennui\",\"indifference\",\"tedious\"},\n",
    "                    \"shame\":{\"abashed\", \"ashamed\", \"embarrassing\", \"humiliating\"},\n",
    "                    \"guilt\":{\"blame\", \"contrition\", \"remorse\"},\n",
    "                    \"disgust\":{\"abhor\", \"aversion\", \"dislike\", \"disrelish\", \"nausea\",\"sick\"},\n",
    "                    \"contempt\":{\"denigration\",\"depreciate\",\"derision\",\"disdain\",\"scorn\"},\n",
    "                    \"hostile\":{},\n",
    "                    \"anger\":{\"anger\",\"angry\",\"furious\",\"fury\",\"incense\",\"infuriating\",\n",
    "                                \"mad\",\"rage\",\"resent\",\"temper\",\"wrath\"},\n",
    "                    \"recognition\":{\"respect\",\"acknowledgement\"}\n",
    "            }\n",
    "\n",
    "vocabulary = []\n",
    "for emotion_group, set_keywords in emotion_words.items():\n",
    "    vocabulary.append(emotion_group)\n",
    "    for word in set_keywords:\n",
    "        vocabulary.append(word)\n",
    "vocabulary = set(vocabulary)\n",
    "\", \".join(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O grande problema é que esse grupo de palavras é muito restrito. Veja como ficou a representação dos nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words(df_amazon_mini,vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que eliminamos as palavras que não apareceram em nenhuma instancia. Assim, como pode-se observar, apenas duas palavras foram usadas e alguns documentos não possuiam nenhuma palavra. Para ampliar o vocabulário, poderiamos expandir esta representação usando palavras similares a estas de acordo com o nosso embedding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
    "dict_embedding = get_embedding(\"glove.en.100.txt\")\n",
    "kdtree_embedding = KDTreeEmbedding(dict_embedding, \"kdt_en.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_expanded = []\n",
    "for word in vocabulary:\n",
    "    #obtem as 40 mais similares palavras de cada uma do vocab original\n",
    "    _,words = kdtree_embedding.get_most_similar_embedding(word,40)\n",
    "    vocabulary_expanded.extend(words)\n",
    "vocabulary_expanded = set(vocabulary_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja aqui as palavras usadas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(vocabulary_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas palavras podem não estar relacionadas à emoção, porém, o método de aprendizado de máquina ainda é capaz de considerar palavras mais relevantes para uma determinada instancia, ignorando algum ruído. Veja como ficou a representação: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words(df_amazon_mini,vocabulary_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderiamos agrupar as palavras chaves em conceitos, por exemplo, \"happiness\" ser sempre contabilizado quando houver um conjunto de palavras, por exemplo, '\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"'. Porém, isso pode restringir muito o número de palavras e expandir com palavras usando embeddings, pode extrair palavras relacionadas com a emoção oposta (veja exemplo abaixo). Por isso, optamos por apresentar a representação usando bag of words. Mesmo assim, caso queira ver algum resultado dessa forma, a classe CountWords implementa expansão por grupos de palavras chaves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distance, words = kdtree_embedding.get_most_similar_embedding(\"happy\",40)\n",
    "#veja que unhappy é relacionado com happy - além de outras palavras negativas e ruido\n",
    "\", \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.textual_representation import CountWords,InstanceWisePreprocess\n",
    "aggregate = CountWords(dict_embedding, emotion_words,max_distance=0.3)\n",
    "\n",
    "word_counter = InstanceWisePreprocess(\"word-counter\",aggregate)\n",
    "word_counter.preprocess_train_dataset(df_amazon_mini, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O max_distance é resposável por obter as palavras similares. Veja que diversos documentos negativos foram classficados com o grupo \"happiness\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representação agregando embeddings das palavras: ** Conforme proposto por [Shen et al.](https://arxiv.org/pdf/1805.09843.pdf), dado que uma frase é representado por um conjunto de embeddings $\\{e_1, e_2, ..., e_n\\}$  uma forma simples e que geralmente obtém resultados **comparáveis a métodos mais complexos** é fazer operações em cada dimensão do embedding, tais como: média e máximo por dimensão do embedding. Por exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings de alguams palavras: \n",
    "dict_embedding = {'my':      [10, 11,14, 20, 15, 80],\n",
    "                  'house':   [11, 12,10, 24, 11, 30],\n",
    "                  'is':      [1,  3,  5, -1, 10, 20],\n",
    "                  'green':   [12,10, 20, 12, 10, 20]\n",
    "                   }\n",
    "#representação do texto \"my house is green\"\n",
    "arr_texto = \"my house is green\".split()\n",
    "arr_texto      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando a média de cada dimensão dos embeddings:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def average_pooling(arr_texto, dim_embedding):\n",
    "    representacao = []\n",
    "    for i in range(dim_embedding):\n",
    "        #calcula a média da iésima posição do embedding\n",
    "        sum_pos = 0\n",
    "        for word in arr_texto:\n",
    "            sum_pos += dict_embedding[word][i]\n",
    "\n",
    "        representacao.append(sum_pos/len(arr_texto))\n",
    "    return representacao\n",
    "dim_embedding = 6\n",
    "representacao = average_pooling(arr_texto, dim_embedding)\n",
    "print(f\"Representação: {representacao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando o máximo de cada dimensão dos embeddings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_embedding = 6\n",
    "def max_pooling(arr_texto, dim_embedding):\n",
    "    representacao = []\n",
    "    for i in range(dim_embedding):\n",
    "        #calcula o valor máximo de cada iésima posição do embedding\n",
    "        first_word = arr_texto[0]\n",
    "        max_pos = dict_embedding[first_word][i]\n",
    "        for word in arr_texto[1:]:\n",
    "            if max_pos < dict_embedding[word][i]:\n",
    "                max_pos = dict_embedding[word][i]\n",
    "\n",
    "        representacao.append(max_pos)\n",
    "    return representacao\n",
    "representacao = max_pooling(arr_texto, dim_embedding)\n",
    "print(f\"Representação: {representacao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como há palavras pouco relevantes (como stopwords) podemos remove-las e, também podemos utilizar apenas as palavras de um vocabulario controlado. Abaixo veja a representação. Como esta representação é vetorial, a mesma não é uma representação simples de ser entendida por humanos, porém, pode-se obter bons resultados. Você pode adicionar o vocabulario controlado ou as stopwords por meio dos parametros correpondentes. O parametro `aggregate_method` define se será feito um maximo ou média entre os embeddings colocando os valores `max` ou `avg`, respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.textual_representation import AggregateEmbeddings,InstanceWisePreprocess\n",
    "dict_embedding = get_embedding(\"glove.en.100.txt\")\n",
    "aggregate_keywords_exp = AggregateEmbeddings(dict_embedding, aggregate_method=\"avg\", \n",
    "                                            words_to_filter=stop_words, words_to_consider=vocabulary_expanded)\n",
    "emb_keywords_exp = InstanceWisePreprocess(\"emb_keywords_exp\",aggregate_keywords_exp)\n",
    "emb_keywords_exp.preprocess_train_dataset(df_amazon_mini, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação por meio de um método de aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os embeddings podem oferecer uma informação de proximidade de conceitos que o uso de Bag of Words não seria capaz. Mesmo assim, cada representação e preprocessamento tem sua vantagem e desvantagem e não existe um método que será sempre o melhor. Assim, para sabermos qual representação é melhor para uma tarefa, é importante avaliarmos em quais delas são maiores para a tarefa em questão. Como o foco desta prática não é a avaliação, iremos apenas apresentar o resultado, caso queira, você pode [assistir a video aula](https://www.youtube.com/watch?v=Ag06UuWTsr4&list=PLwIaU1DGYV6tUx10fCTw5aPnqypbbK_GJ&index=12) e [fazer a prática sobre avaliação](https://github.com/daniel-hasan/ap-de-maquina-cefetmg-avaliacao/archive/master.zip). Nesta parte, iremos apenas usar a avaliação para verificar qual método é melhor.  \n",
    "\n",
    "Para que esta seção seja auto contida, iremos fazer toda a preparação que fizemos nas seções anteriores\n",
    "\n",
    "**Criação da lista de stopwords e de vocabulário:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.utils import get_embedding, KDTreeEmbedding\n",
    "\n",
    "emotion_words = {\n",
    "                    \"pride\":{\"proud\"},\n",
    "                    \"elation\":{\"ecstatic\", \"euphoria\", \"exaltation\", \"exhilarating\"},#vs boredom\n",
    "                    \"happiness\":{\"joy\",\"cheer\", \"bliss\", \"delight\", \"enjoy\", \"happy\"},#vs sad\n",
    "                    \"satisfaction\":{\"comfortable\",\"contentment\"},#\n",
    "                    \"relief\":{},\n",
    "                    \"hope\":{\"buoyancy\", \"confident\", \"faith\", \"optimistic\"},\n",
    "                    \"interest\":{\"alert\", \"animation\", \"ardor\", \"curious\",\"enthusiasm\"},\n",
    "                    \"surprise\":{\"amazed\", \"astonishing\", \"dumbfounded\",\"thunderstruck\"},\n",
    "                    \"anxiety\":{\"anguish\",\"anxiety\",\"apprehensive\",\"jittery\",\"nervous\",\"worry\"},\n",
    "                    \"sadness\":{\"chagrin\", \"dejected\", \"gloom\", \"hopeless\", \"melancholy\", \"sad\", \"tear\"},\n",
    "                    \"boredom\":{\"ennui\",\"indifference\",\"tedious\"},\n",
    "                    \"shame\":{\"abashed\", \"ashamed\", \"embarrassing\", \"humiliating\"},\n",
    "                    \"guilt\":{\"blame\", \"contrition\", \"remorse\"},\n",
    "                    \"disgust\":{\"abhor\", \"aversion\", \"dislike\", \"disrelish\", \"nausea\",\"sick\"},\n",
    "                    \"contempt\":{\"denigration\",\"depreciate\",\"derision\",\"disdain\",\"scorn\"},\n",
    "                    \"hostile\":{},\n",
    "                    \"anger\":{\"anger\",\"angry\",\"furious\",\"fury\",\"incense\",\"infuriating\",\n",
    "                                \"mad\",\"rage\",\"resent\",\"temper\",\"wrath\"},\n",
    "                    \"recognition\":{\"respect\",\"acknowledgement\"}\n",
    "            }\n",
    "dict_embedding = get_embedding(\"glove.en.100.txt\") \n",
    "kdtree_embedding = KDTreeEmbedding(dict_embedding, \"kdt_en.p\")\n",
    "\n",
    "#obtem as stopwords\n",
    "stop_words = set()\n",
    "with open(\"datasets/stopwords.txt\") as stop_file:\n",
    "    stop_words = set(stop_word[:-1] for stop_word in stop_file)\n",
    "\n",
    "\n",
    "#palavras chaves a serem consideradas\n",
    "set_vocabulary = set()\n",
    "for key_word, arr_related_words in emotion_words.items():\n",
    "    set_vocabulary.add(key_word)\n",
    "    set_vocabulary = set_vocabulary | set(arr_related_words)\n",
    "\n",
    "#kdtree - para gerar o conjunto com palavras chaves e suas similares\n",
    "vocabulary_expanded = []\n",
    "for word in set_vocabulary:\n",
    "    _, words = kdtree_embedding.get_most_similar_embedding(word,60)\n",
    "    vocabulary_expanded.extend(words)\n",
    "vocabulary_expanded = set(vocabulary_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Representações usadas**:Iremos avaliar a filtragem de stopwords e usando um vocabulário restrito da representação bag of words e também da representação usando a média de embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings.textual_representation import BagOfWords, AggregateEmbeddings,InstanceWisePreprocess\n",
    "\n",
    "#gera as representações\n",
    "aggregate = AggregateEmbeddings(dict_embedding, \"avg\")\n",
    "embedding = InstanceWisePreprocess(\"embbeding\",aggregate)\n",
    "\n",
    "aggregate_stop = AggregateEmbeddings(dict_embedding, \"avg\",words_to_filter=stop_words)\n",
    "emb_nostop = InstanceWisePreprocess(\"emb_nostop\",aggregate_stop)\n",
    "\n",
    "\n",
    "aggregate_keywords_exp = AggregateEmbeddings(dict_embedding, \"avg\",words_to_consider=vocabulary_expanded)\n",
    "emb_keywords_exp = InstanceWisePreprocess(\"emb_keywords_exp\",aggregate_keywords_exp)\n",
    "\n",
    "bow_keywords = BagOfWords(\"bow_keywords_exp\", words_to_consider=vocabulary_expanded)\n",
    "bow = BagOfWords(\"bow\", stop_words=stop_words)\n",
    "\n",
    "arr_representations = [embedding,emb_nostop, emb_keywords_exp, bow,bow_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, é executado um método de aprendizado  para cada representação. Esse processo pode demorar um pouco pois é feito a procura do melhor parametro do algoritmo. Algumas otimizações que talvez, você precise fazer é no arquivo `embedding/avaliacao_embedding.py` alterar o parametro `n_jobs` no método `obtem_metodo` da classe `OtimizacaoObjetivoRandomForest`. Esse parametro é responsável por utiizar mais threads ao executar o Random Forests.  O valor pode ser levemente inferior a quantidades de núcleos que seu computador tem, caso ele tenha mais de 2, caso contrário, o ideal é colocarmos `n_jobs=1`. Caso queira visualizar resultados mais rapidamente, diminua o valor da variável `num_trials` e `num_folds` abaixo. Atenção que `num_folds` deve ser um valor maior que um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from embeddings.avaliacao_embedding import calcula_experimento_representacao, OtimizacaoObjetivoRandomForest\n",
    "\n",
    "# Método de aprendizado de máquina a ser usado\n",
    "dict_metodo = {\"random_forest\":{\"classe_otimizacao\":OtimizacaoObjetivoRandomForest,\n",
    "                                \"sampler\":optuna.samplers.TPESampler(seed=1, n_startup_trials=10)},\n",
    "              }\n",
    "df_amazon_reviews = pd.read_csv(\"datasets/amazon_reviews_mini.txt\",index_col=\"id\")\n",
    "\n",
    "#executa experimento com a representacao determinada e o método\n",
    "for metodo, param_metodo in dict_metodo.items():\n",
    "    for representation in arr_representations:\n",
    "        print(f\"===== Representação: {representation.nome}\")\n",
    "        col_classe = \"class\"\n",
    "        num_folds = 5\n",
    "        num_folds_validacao = 3\n",
    "        num_trials = 100\n",
    "\n",
    "\n",
    "        nom_experimento = f\"{metodo}_\"+representation.nome\n",
    "        experimento = calcula_experimento_representacao(nom_experimento,representation,df_amazon_reviews,\n",
    "                                            col_classe,num_folds,num_folds_validacao,num_trials,\n",
    "                                            ClasseObjetivoOtimizacao=param_metodo['classe_otimizacao'],\n",
    "                                                sampler=param_metodo['sampler'])\n",
    "        print(f\"Representação: {representation.nome} concluida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a experimentação é uma tarefa custosa, todos os resultados são salvos na pasta \"resultados\" - inclusive os valores dos parametros na classe optuna (a prática de avaliação apresenta mais detalhes da biblioteca Optuna). A macro f1 é uma métrica relacionada a taxa de acerto (se necessário, [veja a explicação neste video - tópico 2 e 3)](https://www.youtube.com/watch?v=u7o7CSeXaNs&list=PLwIaU1DGYV6tUx10fCTw5aPnqypbbK_GJ&index=13). Analise os resultados abaixo: qual representação foi melhor? A restrição de vocabulário ou eliminação de stopwords auxiliou? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from base_am.avaliacao import Experimento\n",
    "\n",
    "arr_resultado = []\n",
    "for resultado_csv in os.listdir(\"resultados\"):\n",
    "    if resultado_csv.endswith(\"csv\"):\n",
    "        nom_experimento = resultado_csv.split(\".\")[0]\n",
    "        \n",
    "        #carrega resultados previamente realizados\n",
    "        experimento = Experimento(nom_experimento,[])\n",
    "        experimento.carrega_resultados_existentes()\n",
    "        \n",
    "        #adiciona experimento\n",
    "        num_folds = len(experimento.resultados)\n",
    "        dict_resultados = {\"nom_experimento\":nom_experimento, \n",
    "                            \"macro-f1\":sum([r.macro_f1 for r in experimento.resultados])/num_folds}\n",
    "        #resultados por classe\n",
    "        for classe in experimento.resultados[0].mat_confusao.keys():\n",
    "\n",
    "            dict_resultados[f\"f1-{classe}\"] = sum([r.f1_por_classe[classe] for r in experimento.resultados])/num_folds\n",
    "            dict_resultados[f\"precision-{classe}\"] = sum([r.precisao[classe] for r in experimento.resultados])/num_folds\n",
    "            dict_resultados[f\"recall-{classe}\"] = sum([r.revocacao[classe] for r in experimento.resultados])/num_folds\n",
    "\n",
    "        arr_resultado.append(dict_resultados)\n",
    "\n",
    "pd.DataFrame.from_dict(arr_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolukbasi, T., Chang, K. W., Zou, J., Saligrama, V., & Kalai, A. (2016). **[Man is to computer programmer as woman is to homemaker? Debiasing word embeddings](https://arxiv.org/abs/1607.06520)**. \n",
    "\n",
    "Hartmann, N., Fonseca, E., Shulby, C., Treviso, M., Rodrigues, J., & Aluisio, S. (2017). [**Portuguese word embeddings: Evaluating on word analogies and natural language tasks.**](https://arxiv.org/abs/1708.06025)\n",
    "\n",
    "\n",
    "Pennington, J., Socher, R., & Manning, C. D. (2014, October).**[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)**. In EMNLP 2015 \n",
    "\n",
    "\n",
    "Scherer, Klaus R. **[What are emotions? And how can they be measured?](https://journals.sagepub.com/doi/pdf/10.1177/0539018405058216)**. Social science information, v. 44, n. 4, p. 695-729, 2005.\n",
    "\n",
    "Shen, D., Wang, G., Wang, W., Min, M. R., Su, Q., Zhang, Y., Carin, L. (2018). [Baseline needs more love: On simple word-embedding-based models and associated pooling mechanisms](https://arxiv.org/pdf/1805.09843.pdf).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Licença Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />Este obra está licenciado com uma Licença <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
